# -*- coding: utf-8 -*-
"""Image_Classification_Final_catsvsdogs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eXwm_KBIpdXnKObswKfpUcxYF_WkqXyr
"""

#install kaggle library
!pip install kaggle

#upload kaggle json file

#configuring path of kaggle.json file
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

#importings Dogs vs Cats Dataset
#Using API to fetch the dataset
!kaggle datasets download -d salader/dogs-vs-cats

#extract the zip file
import zipfile
zip_ref = zipfile.ZipFile('/content/dogs-vs-cats.zip', 'r')
zip_ref.extractall('/content')
zip_ref.close()

#import necessory libraries
import tensorflow as tf
from tensorflow import keras
from keras import Sequential
from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,BatchNormalization,Dropout     #layers imported for CNN Model

#create generators
#divide datas in batches -create less RAM
# Typed Keras image dataset on google- got this code
train_ds= keras.utils.image_dataset_from_directory(
    directory = '/content/train',
    labels="inferred",
    label_mode="int",
    batch_size=32,
    image_size=(256, 256)
)

test_ds= keras.utils.image_dataset_from_directory(
    directory = '/content/test',
    labels="inferred",
    label_mode="int",
    batch_size=32,
    image_size=(256, 256)
)

#normalization

def normal(image,label):
  image = tf.cast(image/255. ,tf.float32)
  return image,label

train_ds = train_ds.map(normal)
test_ds = test_ds.map(normal)
#use map function to apply normalization to every image

"""CNN Model"""

#create layers
model = Sequential()
model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(256,256,3)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))

model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))

model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))

model.add(Flatten())

model.add(Dense(128,activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(64,activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(1,activation='sigmoid'))

from tensorflow.keras.preprocessing.image import ImageDataGenerator

#see summary of the model
model.summary()

#Before fitting, compile the data
model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

history = model.fit(train_ds,epochs=10,validation_data=test_ds)

from tensorflow.keras.preprocessing.image import ImageDataGenerator



import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], color='red', label='train')
plt.plot(history.history['val_accuracy'], color='blue', label='test')
plt.legend()
plt.show()

plt.plot(history.history['loss'], color='red', label='train')
plt.plot(history.history['loss'], color='blue', label='test')
plt.legend()
plt.show()

import cv2

#download images of Cats and Dogs-upload it ti files- use it for testing

test_img= cv2.imread('/content/maltese-portrait.jpg')
plt.imshow(test_img)

#find out size of the image
test_img.shape

test_img = cv2.resize(test_img,(256,256))
test_input = test_img.reshape((1,256,256,3))

model.predict(test_input)

#model is able to predict the images

#new cat image
test_img1= cv2.imread('/content/August_2010-4.jpg')
plt.imshow(test_img1)

test_img1.shape

from google.colab import files
uploaded = files.upload()

#tested the image classification- by uploading a new image
import numpy as np
import cv2
import matplotlib.pyplot as plt

def predict_image_class(image_path):
    # Read and preprocess image
    test_img = cv2.imread(image_path)
    test_img = cv2.resize(test_img, (256, 256))
    test_input = test_img.reshape((1, 256, 256, 3))
    test_input = test_input / 255.0  # Normalize pixel values to [0, 1]

    # Predict using your trained model
    prediction = model.predict(test_input)[0][0]

    # Assign label and calculate confidence
    label = "Dog" if prediction > 0.5 else "Cat"
    confidence = prediction if prediction > 0.5 else 1 - prediction

    # Display result
    print(f"The image is a picture of a {label}. (Confidence: {confidence:.2f})")

    # Show the image with prediction
    plt.imshow(cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB))
    plt.title(f"Predicted: {label}")
    plt.axis('off')
    plt.show()

# Call the function with uploaded image
predict_image_class('guesstheanimal.jpg')

from google.colab import files
uploaded = files.upload()

# Call the function with uploaded image
predict_image_class('/content/guesswho.jpeg')

# Evaluate Model Performance
from sklearn.metrics import classification_report
import numpy as np

y_true = []
y_pred = []

for images, labels in test_ds:
    predictions = model.predict(images)
    predicted_labels = (predictions > 0.5).astype(int).flatten()
    y_true.extend(labels.numpy())
    y_pred.extend(predicted_labels)

print(classification_report(y_true, y_pred, target_names=["Cat", "Dog"]))

#Improve Training Visualization
# Accuracy
plt.plot(history.history['accuracy'], label='Train Accuracy', color='green')
plt.plot(history.history['val_accuracy'], label='Test Accuracy', color='orange')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

# Loss
plt.plot(history.history['loss'], label='Train Loss', color='green')
plt.plot(history.history['val_loss'], label='Test Loss', color='orange')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()